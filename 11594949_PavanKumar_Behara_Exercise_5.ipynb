{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PvanKumarBehara/Pavan_INFO5731_Fall2022/blob/main/11594949_PavanKumar_Behara_Exercise_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xdo_iOmSqvNb"
      },
      "source": [
        "# **The fifth in-class-exercise (40 points in total, 4/18/2023)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Lxgs23HqvNc"
      },
      "source": [
        "(20 points) The purpose of the question is to practice different machine learning algorithms for text classification as well as the performance evaluation. In addition, you are requried to conduct *10 fold cross validation (https://scikit-learn.org/stable/modules/cross_validation.html)* in the training. \n",
        "\n",
        "The dataset can be download from canvas. The dataset contains two files train data and test data for sentiment analysis in IMDB review, it has two categories: 1 represents positive and 0 represents negative. You need to split the training data into training and validate data (80% for training and 20% for validation, https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6) and perform 10 fold cross validation while training the classifier. The final trained model was final evaluated on the test data. \n",
        "\n",
        "Algorithms:\n",
        "\n",
        "(1) MultinominalNB\n",
        "\n",
        "(2) SVM \n",
        "\n",
        "(3) KNN \n",
        "\n",
        "(4) Decision tree\n",
        "\n",
        "(5) Random Forest\n",
        "\n",
        "(6) XGBoost\n",
        "\n",
        "(7) Word2Vec\n",
        "\n",
        "(8) BERT\n",
        "\n",
        "Evaluation measurement:\n",
        "\n",
        "(1) Accuracy\n",
        "\n",
        "(2) Recall\n",
        "\n",
        "(3) Precison \n",
        "\n",
        "(4) F-1 score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNgcaClCqvNd"
      },
      "outputs": [],
      "source": [
        "# Write your code here\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training dataset"
      ],
      "metadata": {
        "id": "vIs6HlEWrixR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"stsa-train.txt\") as txtf:\n",
        "    mylist = [line.rstrip('\\n') for line in txtf]\n",
        "    \n",
        "labels = []\n",
        "text = []\n",
        "\n",
        "for i, line in enumerate(mylist):\n",
        "    label = mylist[i][0]\n",
        "    tex = mylist[i][1:]\n",
        "    labels.append(label)\n",
        "    text.append(tex)\n",
        "\n",
        "dataset = pd.DataFrame(list(zip(labels, text)),columns =['Reviews', 'Text'])\n",
        "dataset.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "PFEaZM5KrW_J",
        "outputId": "159d165b-500b-4017-c2c7-9c981324a39b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Reviews                                               Text\n",
              "0       1   a stirring , funny and finally transporting r...\n",
              "1       0   apparently reassembled from the cutting-room ...\n",
              "2       0   they presume their audience wo n't sit still ...\n",
              "3       1   this is a visually stunning rumination on lov...\n",
              "4       1   jonathan parker 's bartleby should have been ..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-121c2b77-d7cc-47fd-b250-ca14de734dbd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>a stirring , funny and finally transporting r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>apparently reassembled from the cutting-room ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>they presume their audience wo n't sit still ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>this is a visually stunning rumination on lov...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>jonathan parker 's bartleby should have been ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-121c2b77-d7cc-47fd-b250-ca14de734dbd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-121c2b77-d7cc-47fd-b250-ca14de734dbd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-121c2b77-d7cc-47fd-b250-ca14de734dbd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training data preprocessing"
      ],
      "metadata": {
        "id": "_Nr0i-iwrrtw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download()\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmer = PorterStemmer() \n",
        "\n",
        "def preprocess(sentence):\n",
        "    sentence=str(sentence)\n",
        "    sentence = sentence.lower()\n",
        "    sentence=sentence.replace('{html}',\"\") \n",
        "    cleanr = re.compile('<.*?>')\n",
        "    cleantext = re.sub(cleanr, '', sentence)\n",
        "    rem_url=re.sub(r'http\\S+', '',cleantext)\n",
        "    rem_num = re.sub('[0-9]+', '', rem_url)\n",
        "    tokenizer = RegexpTokenizer(r'\\w+')\n",
        "    tokens = tokenizer.tokenize(rem_num)  \n",
        "    filtered_words = [w for w in tokens if len(w) > 2 if not w in stopwords.words('english')]\n",
        "    stem_words=[stemmer.stem(w) for w in filtered_words]\n",
        "    lemma_words=[lemmatizer.lemmatize(w) for w in stem_words]\n",
        "    return \" \".join(filtered_words)\n",
        "\n",
        "\n",
        "dataset['cleanText']=dataset['Text'].map(lambda s:preprocess(s)) \n",
        "dataset.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Lu-4moJrokc",
        "outputId": "9e0fe4f9-7626-4986-e33c-fbb893c776dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing dataset"
      ],
      "metadata": {
        "id": "WS6otw2-sSLx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"stsa-test.txt\") as txtf:\n",
        "    mylist_test = [line.rstrip('\\n') for line in txtf]\n",
        "    \n",
        "labels_test = []\n",
        "text_test = []\n",
        "\n",
        "for i, line in enumerate(mylist_test):\n",
        "    label_test = mylist_test[i][0]\n",
        "    tex_test = mylist_test[i][1:]\n",
        "    labels_test.append(label_test)\n",
        "    text_test.append(tex_test)\n",
        "\n",
        "dataset_test = pd.DataFrame(list(zip(labels_test, text_test)),columns =['Reviews', 'Text'])\n",
        "dataset_test.head()"
      ],
      "metadata": {
        "id": "RK7bZpdBsMOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing data preprocessing"
      ],
      "metadata": {
        "id": "Kf5499bDspsW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download()\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmer = PorterStemmer() \n",
        "\n",
        "def preprocess(sentence):\n",
        "    sentence=str(sentence)\n",
        "    sentence = sentence.lower()\n",
        "    sentence=sentence.replace('{html}',\"\") \n",
        "    cleanr = re.compile('<.*?>')\n",
        "    cleantext = re.sub(cleanr, '', sentence)\n",
        "    rem_url=re.sub(r'http\\S+', '',cleantext)\n",
        "    rem_num = re.sub('[0-9]+', '', rem_url)\n",
        "    tokenizer = RegexpTokenizer(r'\\w+')\n",
        "    tokens = tokenizer.tokenize(rem_num)  \n",
        "    filtered_words = [w for w in tokens if len(w) > 2 if not w in stopwords.words('english')]\n",
        "    stem_words=[stemmer.stem(w) for w in filtered_words]\n",
        "    lemma_words=[lemmatizer.lemmatize(w) for w in stem_words]\n",
        "    return \" \".join(filtered_words)\n",
        "\n",
        "\n",
        "dataset_test['cleanText']=dataset_test['Text'].map(lambda s:preprocess(s)) \n",
        "dataset_test.head()"
      ],
      "metadata": {
        "id": "AL72JlQbsW7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF-IDF Vectorization"
      ],
      "metadata": {
        "id": "Kz-Bt2UIs1-g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer \n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer(lowercase = False, analyzer='word')\n",
        "train_tfidf = tfidf_vectorizer.fit_transform(dataset[\"cleanText\"]).toarray()\n",
        "test_tfidf = tfidf_vectorizer.transform(dataset_test[\"cleanText\"]).toarray()"
      ],
      "metadata": {
        "id": "jaZTSmhcst1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = test_tfidf\n",
        "y_test = dataset_test[\"Reviews\"]"
      ],
      "metadata": {
        "id": "uZHJ3Uf_s8Af"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data partitioning"
      ],
      "metadata": {
        "id": "PHQvKnootLVi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(train_tfidf,dataset[\"Reviews\"],test_size = 0.2, random_state = 202)"
      ],
      "metadata": {
        "id": "Fo1nwYxxtUd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Algorithms\n",
        "1. MultinominalNB"
      ],
      "metadata": {
        "id": "Pi_23MxNttXx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "classifier = MultinomialNB()\n",
        "model = classifier.fit(x_train, y_train) \n",
        "predictions_validation_set = classifier.predict(x_valid) \n",
        "\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "print (\"Accuracy of the Naive Bayes model on validation set is : \", round(accuracy_score(y_valid, predictions_validation_set)*100),\"%\")\n",
        "print (\"Percision of the Naive Bayes model on validation set is : \", round(precision_score(y_valid, predictions_validation_set, pos_label='0')*100),\"%\")\n",
        "print (\"Recall of the Naive Bayes model on validation set is : \", round(recall_score(y_valid, predictions_validation_set, pos_label='0')*100),\"%\")\n",
        "print (\"F1 Score of the Naive Bayes model on validation set is : \", round(f1_score(y_valid, predictions_validation_set, pos_label='0')*100),\"%\")"
      ],
      "metadata": {
        "id": "1SSjKheftfXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "cr_naive_validation = classification_report(y_valid, predictions_validation_set)\n",
        "print(\"Classification Report: \", \"\\n\", \"\\n\",cr_naive_validation)\n"
      ],
      "metadata": {
        "id": "v1EUcb80t5QL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "naive_accuracies_validation = cross_val_score(estimator = classifier, X = x_train, y = y_train, cv = 10)\n",
        "\n",
        "print(f\"Naive Bayes Model  10-fold cross validation score on training set is :  {round(naive_accuracies_validation.mean()*100)}%\")"
      ],
      "metadata": {
        "id": "s_ljBoHwuJ9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_test_set = classifier.predict(x_test) \n",
        "print (\"Accuracy of the Naive Bayes model on test set is : \", round(accuracy_score(y_test, predictions_test_set)*100),\"%\")\n",
        "print (\"Percision of the Naive Bayes model on validation set is : \", round(precision_score(y_test, predictions_test_set, pos_label='0')*100),\"%\")\n",
        "print (\"Recall of the Naive Bayes model on validation set is : \", round(recall_score(y_test, predictions_test_set, pos_label='0')*100),\"%\")\n",
        "print (\"F1 Score of the Naive Bayes model on validation set is : \", round(f1_score(y_test, predictions_test_set, pos_label='0')*100),\"%\")"
      ],
      "metadata": {
        "id": "eZbUlZdxu13i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cr_naive_test = classification_report(y_test, predictions_test_set)\n",
        "print(\"Classification Report: \", \"\\n\", \"\\n\",cr_naive_test)"
      ],
      "metadata": {
        "id": "fQinyho1u_cU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "naive_accuracies_test = cross_val_score(estimator = classifier, X = x_test, y = y_test, cv = 10)\n",
        "\n",
        "print(f\"Naive Bayes Model 10-fold cross validation score on testing set is :  {round(naive_accuracies_test.mean()*100)}%\")"
      ],
      "metadata": {
        "id": "9zvWsp56vI7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVM"
      ],
      "metadata": {
        "id": "pGVkSjcpxj5S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "\n",
        "classifier_svm = svm.SVC()\n",
        "model_svm = classifier_svm.fit(x_train, y_train) \n",
        "svm_predictions_validation_set = classifier_svm.predict(x_valid) \n",
        "\n",
        "print (\"Accuracy of the SVM model on validation set is : \", round(accuracy_score(y_valid, svm_predictions_validation_set)*100),\"%\")\n",
        "print (\"Percision of the SVM model on validation set is : \", round(precision_score(y_valid, svm_predictions_validation_set, pos_label='0')*100),\"%\")\n",
        "print (\"Recall of the SVM model on validation set is : \", round(recall_score(y_valid, svm_predictions_validation_set, pos_label='0')*100),\"%\")\n",
        "print (\"F1 Score of the SVM model on validation set is : \", round(f1_score(y_valid, svm_predictions_validation_set, pos_label='0')*100),\"%\")"
      ],
      "metadata": {
        "id": "yrlwHRQlvTHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "cr_svm_validation = classification_report(y_valid, svm_predictions_validation_set)\n",
        "print(\"Classification Report: \", \"\\n\", \"\\n\",cr_svm_validation)"
      ],
      "metadata": {
        "id": "piD8m1Y8xm8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "svm_accuracies_validation = cross_val_score(estimator = classifier_svm, X = x_train, y = y_train, cv = 10)\n",
        "\n",
        "print(f\"SVM Model  10-fold cross validation score on training set is :  {round(svm_accuracies_validation.mean()*100)}%\")"
      ],
      "metadata": {
        "id": "5N-zLDpHx16u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svm_predictions_test_set = classifier_svm.predict(x_test) \n",
        "print (\"Accuracy of the SVM model on test set is : \", round(accuracy_score(y_test, svm_predictions_test_set)*100),\"%\")\n",
        "print (\"Percision of the SVM model on validation set is : \", round(precision_score(y_test, svm_predictions_test_set, pos_label='0')*100),\"%\")\n",
        "print (\"Recall of the SVM model on validation set is : \", round(recall_score(y_test, svm_predictions_test_set, pos_label='0')*100),\"%\")\n",
        "print (\"F1 Score of the SVM model on validation set is : \", round(f1_score(y_test, svm_predictions_test_set, pos_label='0')*100),\"%\")"
      ],
      "metadata": {
        "id": "P2Ytry3NBJCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cr_svm_test = classification_report(y_test, svm_predictions_test_set)\n",
        "print(\"Classification Report: \", \"\\n\", \"\\n\",cr_svm_test)"
      ],
      "metadata": {
        "id": "1RnuInn4D8WN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svm_accuracies_test = cross_val_score(estimator = classifier_svm, X = x_test, y = y_test, cv = 10)\n",
        "\n",
        "print(f\"SVM Model 10-fold cross validation score on testing set is :  {round(svm_accuracies_test.mean()*100)}%\")"
      ],
      "metadata": {
        "id": "gB1FN2nYEFJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "KNN"
      ],
      "metadata": {
        "id": "5L8x9FiSmyrR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "classifier_knn = KNeighborsClassifier(n_neighbors = 15)\n",
        "model_knn = classifier_knn.fit(x_train, y_train) \n",
        "knn_predictions_validation_set = classifier_knn.predict(x_valid) \n",
        "\n",
        "print (\"Accuracy of the KNN model on validation set is : \", round(accuracy_score(y_valid, knn_predictions_validation_set)*100),\"%\")\n",
        "print (\"Percision of the KNN model on validation set is : \", round(precision_score(y_valid, knn_predictions_validation_set, pos_label='0')*100),\"%\")\n",
        "print (\"Recall of the KNN model on validation set is : \", round(recall_score(y_valid, knn_predictions_validation_set, pos_label='0')*100),\"%\")\n",
        "print (\"F1 Score of the KNN model on validation set is : \", round(f1_score(y_valid, knn_predictions_validation_set, pos_label='0')*100),\"%\")"
      ],
      "metadata": {
        "id": "teC26DXZFvyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "cr_knn_validation = classification_report(y_valid, knn_predictions_validation_set)\n",
        "print(\"Classification Report: \", \"\\n\", \"\\n\",cr_knn_validation)"
      ],
      "metadata": {
        "id": "UsLlPgK9F7JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "knn_accuracies_validation = cross_val_score(estimator = classifier_knn, X = x_train, y = y_train, cv = 10)\n",
        "\n",
        "print(f\"KNN Model  10-fold cross validation score on training set is :  {round(knn_accuracies_validation.mean()*100)}%\")"
      ],
      "metadata": {
        "id": "VewZpRikF9Dg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn_predictions_test_set = classifier_knn.predict(x_test) \n",
        "print (\"Accuracy of the KNN model on test set is : \", round(accuracy_score(y_test, knn_predictions_test_set)*100),\"%\")\n",
        "print (\"Percision of the KNN model on validation set is : \", round(precision_score(y_test, knn_predictions_test_set, pos_label='0')*100),\"%\")\n",
        "print (\"Recall of the KNN model on validation set is : \", round(recall_score(y_test, knn_predictions_test_set, pos_label='0')*100),\"%\")\n",
        "print (\"F1 Score of the KNN model on validation set is : \", round(f1_score(y_test, knn_predictions_test_set, pos_label='0')*100),\"%\")"
      ],
      "metadata": {
        "id": "gokZruiuGEbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cr_knn_test = classification_report(y_test, knn_predictions_test_set)\n",
        "print(\"Classification Report: \", \"\\n\", \"\\n\",cr_knn_test)"
      ],
      "metadata": {
        "id": "qUu2NpmEGKpn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn_accuracies_test = cross_val_score(estimator = classifier_knn, X = x_test, y = y_test, cv = 10)\n",
        "\n",
        "print(f\"KNN Model 10-fold cross validation score on testing set is :  {round(knn_accuracies_test.mean()*100)}%\")"
      ],
      "metadata": {
        "id": "iKaj1zl8GVQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decison Tree"
      ],
      "metadata": {
        "id": "IWJ1HwVKms0f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "classifier_dt = DecisionTreeClassifier()\n",
        "model_dt = classifier_dt.fit(x_train, y_train) \n",
        "dt_predictions_validation_set = classifier_dt.predict(x_valid) \n",
        "\n",
        "print (\"Accuracy of the Decison Tree Classifier model on validation set is : \", round(accuracy_score(y_valid, dt_predictions_validation_set)*100),\"%\")\n",
        "print (\"Percision of the Decison Tree Classifier model on validation set is : \", round(precision_score(y_valid, dt_predictions_validation_set, pos_label='0')*100),\"%\")\n",
        "print (\"Recall of the Decison Tree Classifier model on validation set is : \", round(recall_score(y_valid, dt_predictions_validation_set, pos_label='0')*100),\"%\")\n",
        "print (\"F1 Score of the Decison Tree Classifier model on validation set is : \", round(f1_score(y_valid, dt_predictions_validation_set, pos_label='0')*100),\"%\")"
      ],
      "metadata": {
        "id": "HlxUxRoZGa9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "cr_dt_validation = classification_report(y_valid, dt_predictions_validation_set)\n",
        "print(\"Classification Report: \", \"\\n\", \"\\n\",cr_dt_validation)"
      ],
      "metadata": {
        "id": "-l0KGhbZHIbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "dt_accuracies_validation = cross_val_score(estimator = classifier_dt, X = x_train, y = y_train, cv = 10)\n",
        "\n",
        "print(f\"Decison Tree Classifier Model  10-fold cross validation score on training set is :  {round(dt_accuracies_validation.mean()*100)}%\")"
      ],
      "metadata": {
        "id": "87Au0l0MHMZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt_predictions_test_set = classifier_dt.predict(x_test) \n",
        "print (\"Accuracy of the Decison Tree Classifier model on test set is : \", round(accuracy_score(y_test, dt_predictions_test_set)*100),\"%\")\n",
        "print (\"Percision of the Decison Tree Classifier model on validation set is : \", round(precision_score(y_test, dt_predictions_test_set, pos_label='0')*100),\"%\")\n",
        "print (\"Recall of the Decison Tree Classifier model on validation set is : \", round(recall_score(y_test, dt_predictions_test_set, pos_label='0')*100),\"%\")\n",
        "print (\"F1 Score of the Decison Tree Classifier model on validation set is : \", round(f1_score(y_test, dt_predictions_test_set, pos_label='0')*100),\"%\")"
      ],
      "metadata": {
        "id": "OnIUDjs1HRJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cr_dt_test = classification_report(y_test, dt_predictions_test_set)\n",
        "print(\"Classification Report: \", \"\\n\", \"\\n\",cr_dt_test)"
      ],
      "metadata": {
        "id": "IErYckFqJLn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt_accuracies_test = cross_val_score(estimator = classifier_dt, X = x_test, y = y_test, cv = 10)\n",
        "\n",
        "print(f\"Decison Tree Classifier Model 10-fold cross validation score on testing set is :  {round(dt_accuracies_test.mean()*100)}%\")"
      ],
      "metadata": {
        "id": "ei5NTer5JT77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Randomforest"
      ],
      "metadata": {
        "id": "8URhnwaGmnwO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "classifier_rf = RandomForestClassifier()\n",
        "model_rf = classifier_rf.fit(x_train, y_train) \n",
        "rf_predictions_validation_set = classifier_rf.predict(x_valid) \n",
        "\n",
        "print (\"Accuracy of the Random Forest Classifier model on validation set is : \", round(accuracy_score(y_valid, rf_predictions_validation_set)*100),\"%\")\n",
        "print (\"Percision of the Random Forest Classifier model on validation set is : \", round(precision_score(y_valid, rf_predictions_validation_set, pos_label='0')*100),\"%\")\n",
        "print (\"Recall of the Random Forest Classifier model on validation set is : \", round(recall_score(y_valid, rf_predictions_validation_set, pos_label='0')*100),\"%\")\n",
        "print (\"F1 Score of the Random Forest Classifier model on validation set is : \", round(f1_score(y_valid, rf_predictions_validation_set, pos_label='0')*100),\"%\")"
      ],
      "metadata": {
        "id": "7cuXgkOLJWNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "cr_rf_validation = classification_report(y_valid, rf_predictions_validation_set)\n",
        "print(\"Classification Report: \", \"\\n\", \"\\n\",cr_rf_validation)"
      ],
      "metadata": {
        "id": "HsdjA4eIJjX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "rf_accuracies_validation = cross_val_score(estimator = classifier_rf, X = x_train, y = y_train, cv = 10)\n",
        "\n",
        "print(f\"Decison Random Forest Model  10-fold cross validation score on training set is :  {round(rf_accuracies_validation.mean()*100)}%\")"
      ],
      "metadata": {
        "id": "H2dwGhLzJnVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_predictions_test_set = classifier_rf.predict(x_test) \n",
        "print (\"Accuracy of the Random Forest Classifier model on test set is : \", round(accuracy_score(y_test, rf_predictions_test_set)*100),\"%\")\n",
        "print (\"Percision of the Random Forest Classifier model on validation set is : \", round(precision_score(y_test, rf_predictions_test_set, pos_label='0')*100),\"%\")\n",
        "print (\"Recall of the Random Forest Classifier model on validation set is : \", round(recall_score(y_test, rf_predictions_test_set, pos_label='0')*100),\"%\")\n",
        "print (\"F1 Score of the Random Forest Classifier model on validation set is : \", round(f1_score(y_test, rf_predictions_test_set, pos_label='0')*100),\"%\")"
      ],
      "metadata": {
        "id": "KhQA9M6lJusk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cr_rf_test = classification_report(y_test, rf_predictions_test_set)\n",
        "print(\"Classification Report: \", \"\\n\", \"\\n\",cr_rf_test)"
      ],
      "metadata": {
        "id": "sA1MLi3AJyZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_accuracies_test = cross_val_score(estimator = classifier_rf, X = x_test, y = y_test, cv = 10)\n",
        "\n",
        "print(f\"Random Forest Classifier Model 10-fold cross validation score on testing set is :  {round(rf_accuracies_test.mean()*100)}%\")"
      ],
      "metadata": {
        "id": "JWavCQNeJ2WZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBoost"
      ],
      "metadata": {
        "id": "8XgxRd9UmhlH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Convert y_train and y_valid to integers\n",
        "y_train = y_train.astype(int)\n",
        "y_valid = y_valid.astype(int)\n",
        "\n",
        "classifier_xgb = XGBClassifier()\n",
        "model_xgb = classifier_xgb.fit(x_train, y_train) \n",
        "xgb_predictions_validation_set = classifier_xgb.predict(x_valid) \n",
        "\n",
        "print (\"Accuracy of the XGBoost Classifier model on validation set is : \", round(accuracy_score(y_valid, xgb_predictions_validation_set)*100),\"%\")\n",
        "print (\"Percision of the XGBoost Classifier model on validation set is : \", round(precision_score(y_valid, xgb_predictions_validation_set, pos_label=0)*100),\"%\")\n",
        "print (\"Recall of the XGBoost Classifier model on validation set is : \", round(recall_score(y_valid, xgb_predictions_validation_set, pos_label=0)*100),\"%\")\n",
        "print (\"F1 Score of the XGBoost Classifier model on validation set is : \", round(f1_score(y_valid, xgb_predictions_validation_set, pos_label=0)*100),\"%\")\n"
      ],
      "metadata": {
        "id": "H8w5otqJJ57R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "cr_xgb_validation = classification_report(y_valid, xgb_predictions_validation_set)\n",
        "print(\"Classification Report: \", \"\\n\", \"\\n\",cr_xgb_validation)"
      ],
      "metadata": {
        "id": "jJJOOx-1KElr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "xgb_accuracies_validation = cross_val_score(estimator = classifier_xgb, X = x_train, y = y_train, cv = 10)\n",
        "\n",
        "print(f\"XGBoost Model  10-fold cross validation score on training set is :  {round(xgb_accuracies_validation.mean()*100)}%\")"
      ],
      "metadata": {
        "id": "RQBJo1GaKJen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_predictions_test_set = classifier_xgb.predict(x_test) \n",
        "print (\"Accuracy of the XGBoost Classifier model on test set is : \", round(accuracy_score(y_test, xgb_predictions_test_set)*100),\"%\")\n",
        "print (\"Percision of the XGBoost Classifier model on validation set is : \", round(precision_score(y_test, xgb_predictions_test_set, pos_label='0')*100),\"%\")\n",
        "print (\"Recall of the XGBoost Classifier model on validation set is : \", round(recall_score(y_test, xgb_predictions_test_set, pos_label='0')*100),\"%\")\n",
        "print (\"F1 Score of the XGBoost Classifier model on validation set is : \", round(f1_score(y_test, xgb_predictions_test_set, pos_label='0')*100),\"%\")"
      ],
      "metadata": {
        "id": "gxXFFNZ1KM2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cr_xgb_test = classification_report(y_test, xgb_predictions_test_set)\n",
        "print(\"Classification Report: \", \"\\n\", \"\\n\",cr_xgb_test)"
      ],
      "metadata": {
        "id": "jXscOPuBKRYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_accuracies_test = cross_val_score(estimator = classifier_xgb, X = x_test, y = y_test, cv = 10)\n",
        "\n",
        "print(f\"XGBoost Classifier Model 10-fold cross validation score on testing set is :  {round(xgb_accuracies_test.mean()*100)}%\")"
      ],
      "metadata": {
        "id": "QppnXhXoKUoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1SB3LeTbKYd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCVSXNj-qvNd"
      },
      "source": [
        "(20 points) The purpose of the question is to practice different machine learning algorithms for text clustering\n",
        "Please downlad the dataset by using the following link.  https://www.kaggle.com/PromptCloudHQ/amazon-reviews-unlocked-mobile-phones\n",
        "(You can also use different text data which you want)\n",
        "\n",
        "Apply the listed clustering methods to the dataset:\n",
        "\n",
        "K-means\n",
        "\n",
        "DBSCAN\n",
        "\n",
        "Hierarchical clustering\n",
        "\n",
        "Word2Vec\n",
        "\n",
        "BERT\n",
        "\n",
        "You can refer to of the codes from  the follwing link below. \n",
        "https://www.kaggle.com/karthik3890/text-clustering "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "K MEANS"
      ],
      "metadata": {
        "id": "QfVBphZdmajZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vH-yZVa4qvNe"
      },
      "outputs": [],
      "source": [
        "#Write your code here.\n",
        "\n",
        "df = pd.read_csv('Amazon_Unlocked_Mobile1.csv')\n",
        "\n",
        "df['Reviews']=df['Reviews'].map(lambda s:preprocess(s)) \n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TF-IDF VECTORIZATION\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf_vect = TfidfVectorizer()\n",
        "tfidf_vects = tfidf_vect.fit_transform(df['Reviews'].values.astype('U'))\n",
        "names= tfidf_vect.get_feature_names()"
      ],
      "metadata": {
        "id": "HgQivd1ZlfPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## ELBOW METHOD\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "wcss = []\n",
        "for i in range(2,12):\n",
        "    kmeans = KMeans(n_clusters = i, init = \"k-means++\", random_state = 101)\n",
        "    kmeans.fit(tfidf_vects)\n",
        "    wcss.append(kmeans.inertia_)\n",
        "\n",
        "plt.figure(figsize = (11,6))\n",
        "plt.plot(range(2,12), wcss, marker = \"o\")\n",
        "plt.title (\"The Elbow Method\")\n",
        "plt.xlabel(\"Number of clusters\")\n",
        "plt.ylabel(\"WCSS\")"
      ],
      "metadata": {
        "id": "SIaADJd5liYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#forming 6 clusters\n",
        "from sklearn.cluster import KMeans\n",
        "model = KMeans(n_clusters = 6,init='k-means++',max_iter=10000, random_state=50)\n",
        "model.fit(tfidf_vects)\n",
        "from collections import Counter\n",
        "Counter(model.labels_)"
      ],
      "metadata": {
        "id": "MzPKl_gpllgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clusters containing words with maximum strength\n",
        "top_words = 7\n",
        "centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
        "for cluster_num in range(6):\n",
        "    key_features = [names[i] for i in centroids[cluster_num, :top_words]]\n",
        "    print('Cluster '+str(cluster_num+1))\n",
        "    print('Top Words:', key_features)"
      ],
      "metadata": {
        "id": "DGRwQoOHlpG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_center=model.cluster_centers_\n",
        "cluster_center"
      ],
      "metadata": {
        "id": "E8_MmnUBlp9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DBSCAN"
      ],
      "metadata": {
        "id": "WIiJp9NtmUac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reviews=[]\n",
        "for i in df['Reviews']:\n",
        "    reviews.append(str(i).split())\n",
        "import gensim\n",
        "w2v_model=gensim.models.Word2Vec(reviews, size=100, workers=4)\n",
        "\n",
        "import numpy as np\n",
        "vectors = []\n",
        "for i in reviews:\n",
        "    vector = np.zeros(100)\n",
        "    count = 0\n",
        "    for word in i:\n",
        "        try:\n",
        "            vec = w2v_model.wv[word]\n",
        "            vector += vec\n",
        "            count += 1\n",
        "        except:\n",
        "            pass\n",
        "    vector /= count\n",
        "    vectors.append(vector)  \n",
        "vectors = np.array(vectors)\n",
        "vectors = np.nan_to_num(vectors)"
      ],
      "metadata": {
        "id": "9j2tdz_also7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "minPts = 2 * 100\n",
        "# Lower bound function\n",
        "def lower_bound(nums, target): \n",
        "    l, r = 0, len(nums) - 1\n",
        "    # Binary searching\n",
        "    while l <= r:\n",
        "        mid = int(l + (r - l) / 2)\n",
        "        if nums[mid] >= target:\n",
        "            r = mid - 1\n",
        "        else:\n",
        "            l = mid + 1\n",
        "    return l\n",
        "\n",
        "def compute200thnearestneighbour(x, data): \n",
        "    dists = []\n",
        "    for val in data:\n",
        "      # computing distances\n",
        "        dist = np.sum((x - val) **2 ) \n",
        "        if(len(dists) == 200 and dists[199] > dist): \n",
        "            l = int(lower_bound(dists, dist)) \n",
        "            if l < 200 and l >= 0 and dists[l] > dist:\n",
        "                dists[l] = dist\n",
        "        else:\n",
        "            dists.append(dist)\n",
        "            dists.sort()\n",
        "\n",
        "# Dist 199 contains the distance of 200th nearest neighbour.    \n",
        "    return dists[199]\n"
      ],
      "metadata": {
        "id": "CMwbvHKOlwTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Computing the 200th nearest neighbour distance of some point the dataset:\n",
        "twohundrethneigh = []\n",
        "for val in vectors[:1000]:\n",
        "    twohundrethneigh.append( compute200thnearestneighbour(val, vectors[:1000]) )\n",
        "twohundrethneigh.sort()"
      ],
      "metadata": {
        "id": "DCdKuUbDlzqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting for the Elbow Method :\n",
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "plt.figure(figsize=(14,4))\n",
        "plt.title(\"Elbow Method for Finding the right Eps hyperparameter\")\n",
        "plt.plot([x for x in range(len(twohundrethneigh))], twohundrethneigh)\n",
        "plt.xlabel(\"Number of points\")\n",
        "plt.ylabel(\"Distance of 200th Nearest Neighbour\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IIcNcnNdl2is"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model\n",
        "model_dbs = DBSCAN(eps = 5, min_samples = minPts)\n",
        "model_dbs.fit(vectors)"
      ],
      "metadata": {
        "id": "Xx-Y5KSsl5w-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_dbs = df\n",
        "df_dbs[\"DBS Cluster Label\"] = model_dbs.labels_\n",
        "df_dbs"
      ],
      "metadata": {
        "id": "3yGSLGWVl8YY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hierarchical clustering"
      ],
      "metadata": {
        "id": "pvkiXXp_mNPV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy\n",
        "from scipy.cluster import hierarchy\n",
        "dendro=hierarchy.dendrogram(hierarchy.linkage(vectors,method='ward'))\n",
        "plt.axhline(y=20)"
      ],
      "metadata": {
        "id": "uKd1XhrYl-4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import AgglomerativeClustering\n",
        "\n",
        "cluster = AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage='ward')  #took n=3 from dendrogram curve \n",
        "Agg=cluster.fit_predict(vectors)"
      ],
      "metadata": {
        "id": "yvNAU3DOmCFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['AVG-W2V Clus Label'] = cluster.labels_\n",
        "df.head()"
      ],
      "metadata": {
        "id": "col7tGsDmHO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hier_df = df # Give the labels and group to count the number of data in each clusters.\n",
        "hier_df[\"Hierarchial Cluster Labels\"] = cluster.labels_\n",
        "hier_df.groupby([\"Hierarchial Cluster Labels\"])[\"Reviews\"].count()"
      ],
      "metadata": {
        "id": "Gg5UM2fGmKC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tB9FCe_cqvNe"
      },
      "source": [
        "In one paragraph, please compare the results of K-means, DBSCAN, Hierarchical clustering, Word2Vec, and BERT."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58Ecc89QqvNe"
      },
      "outputs": [],
      "source": [
        "#You can write you answer here. (No code needed)\n",
        "\n",
        "Strategies for unsupervised clustering Based on the properties of the data points, comparable data points are grouped together using K-means, DBSCAN, and hierarchical clustering. For text-based jobs, on the other hand, natural language processing techniques like Word2Vec and BERT are used.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}